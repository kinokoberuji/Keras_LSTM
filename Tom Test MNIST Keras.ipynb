{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run notebook on other machines at CSS\n",
    "## jupyter notebook --ip xx.xx.xx.xxx --port xxxx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Tutorial 2\n"
     ]
    }
   ],
   "source": [
    "print (\"MNIST Tutorial 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tgibbons\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print (np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 8s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28dbde8c898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28dbdd7ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126\n",
      "   136 175  26 166 255 247 127   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253\n",
      "   253 225 172 253 242 195  64   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253\n",
      "   251  93  82  82  56  39   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247\n",
      "   241   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43\n",
      "   154   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108\n",
      "     1   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253\n",
      "   119  25   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253\n",
      "   253 150  27   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93\n",
      "   252 253 187   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   249 253 249  64   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183\n",
      "   253 253 207   2   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253\n",
      "   253 250 182   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253\n",
      "   201  78   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81\n",
      "     2   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "X_train2 = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test2 = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "print (X_train.shape)\n",
    "print (X_train2.shape)\n",
    "print (X_train[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_norm = X_train / 255\n",
    "X_test_norm = X_test / 255\n",
    "X_train2 = X_train2.astype('float32')\n",
    "X_test2 = X_test2.astype('float32')\n",
    "X_train_norm2 = X_train2 / 255\n",
    "X_test_norm2 = X_test2 / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.01176471]\n",
      "   [0.07058824]\n",
      "   [0.07058824]\n",
      "   [0.07058824]\n",
      "   [0.49411765]\n",
      "   [0.53333336]\n",
      "   [0.6862745 ]\n",
      "   [0.10196079]\n",
      "   [0.6509804 ]\n",
      "   [1.        ]\n",
      "   [0.96862745]\n",
      "   [0.49803922]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.11764706]\n",
      "   [0.14117648]\n",
      "   [0.36862746]\n",
      "   [0.6039216 ]\n",
      "   [0.6666667 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.88235295]\n",
      "   [0.6745098 ]\n",
      "   [0.99215686]\n",
      "   [0.9490196 ]\n",
      "   [0.7647059 ]\n",
      "   [0.2509804 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.19215687]\n",
      "   [0.93333334]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.9843137 ]\n",
      "   [0.3647059 ]\n",
      "   [0.32156864]\n",
      "   [0.32156864]\n",
      "   [0.21960784]\n",
      "   [0.15294118]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.07058824]\n",
      "   [0.85882354]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.7764706 ]\n",
      "   [0.7137255 ]\n",
      "   [0.96862745]\n",
      "   [0.94509804]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.3137255 ]\n",
      "   [0.6117647 ]\n",
      "   [0.41960785]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.8039216 ]\n",
      "   [0.04313726]\n",
      "   [0.        ]\n",
      "   [0.16862746]\n",
      "   [0.6039216 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.05490196]\n",
      "   [0.00392157]\n",
      "   [0.6039216 ]\n",
      "   [0.99215686]\n",
      "   [0.3529412 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.54509807]\n",
      "   [0.99215686]\n",
      "   [0.74509805]\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.04313726]\n",
      "   [0.74509805]\n",
      "   [0.99215686]\n",
      "   [0.27450982]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.13725491]\n",
      "   [0.94509804]\n",
      "   [0.88235295]\n",
      "   [0.627451  ]\n",
      "   [0.42352942]\n",
      "   [0.00392157]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.31764707]\n",
      "   [0.9411765 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.46666667]\n",
      "   [0.09803922]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.1764706 ]\n",
      "   [0.7294118 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.5882353 ]\n",
      "   [0.10588235]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.0627451 ]\n",
      "   [0.3647059 ]\n",
      "   [0.9882353 ]\n",
      "   [0.99215686]\n",
      "   [0.73333335]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.9764706 ]\n",
      "   [0.99215686]\n",
      "   [0.9764706 ]\n",
      "   [0.2509804 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.18039216]\n",
      "   [0.50980395]\n",
      "   [0.7176471 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.8117647 ]\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.15294118]\n",
      "   [0.5803922 ]\n",
      "   [0.8980392 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.98039216]\n",
      "   [0.7137255 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.09411765]\n",
      "   [0.44705883]\n",
      "   [0.8666667 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.7882353 ]\n",
      "   [0.30588236]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.09019608]\n",
      "   [0.25882354]\n",
      "   [0.8352941 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.7764706 ]\n",
      "   [0.31764707]\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.07058824]\n",
      "   [0.67058825]\n",
      "   [0.85882354]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.7647059 ]\n",
      "   [0.3137255 ]\n",
      "   [0.03529412]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.21568628]\n",
      "   [0.6745098 ]\n",
      "   [0.8862745 ]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.95686275]\n",
      "   [0.52156866]\n",
      "   [0.04313726]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.53333336]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.99215686]\n",
      "   [0.83137256]\n",
      "   [0.5294118 ]\n",
      "   [0.5176471 ]\n",
      "   [0.0627451 ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "print (X_train_norm2.shape)\n",
    "print (X_train_norm2[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print (y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "print (Y_train.shape)\n",
    "print (Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tgibbons\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(Conv2D(32,(3,3), border_mode='same',kernel_initializer='uniform',input_shape=(28,28,1),dim_ordering='tf',name='conv_1.1'))\n",
    "#model.add(Conv2D(16, 3,3, border_mode='same', input_shape=(1, 28, 28), activation='relu'))\n",
    "#model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28,28)))\n",
    "#model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#model.add(Dense(32, activation='relu', input_dim=(28*28)))\n",
    "#model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Compile model\n",
    "model.compile(optimizer='adam',            loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 29s 478us/step - loss: 0.3527 - acc: 0.8934 - val_loss: 0.1064 - val_acc: 0.9692\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 28s 467us/step - loss: 0.1441 - acc: 0.9573 - val_loss: 0.0649 - val_acc: 0.9798\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 27s 458us/step - loss: 0.1056 - acc: 0.9686 - val_loss: 0.0564 - val_acc: 0.9814\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 29s 483us/step - loss: 0.0884 - acc: 0.9740 - val_loss: 0.0480 - val_acc: 0.9837\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.0787 - acc: 0.9760 - val_loss: 0.0465 - val_acc: 0.9852\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.0702 - acc: 0.9779 - val_loss: 0.0439 - val_acc: 0.9855\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 27s 457us/step - loss: 0.0633 - acc: 0.9804 - val_loss: 0.0400 - val_acc: 0.9866\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0580 - acc: 0.9822 - val_loss: 0.0404 - val_acc: 0.9863\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.0531 - acc: 0.9830 - val_loss: 0.0376 - val_acc: 0.9874\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.0486 - acc: 0.9847 - val_loss: 0.0384 - val_acc: 0.9871\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 27s 452us/step - loss: 0.0442 - acc: 0.9858 - val_loss: 0.0383 - val_acc: 0.9870\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 27s 453us/step - loss: 0.0414 - acc: 0.9867 - val_loss: 0.0404 - val_acc: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28db8c05ac8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Fit model on training data\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "#model.fit(X_train, Y_train, batch_size=32, epoch=10, verbose=1)\n",
    "#model.fit(X_train, Y_train, batch_size=32, epochs=10)\n",
    "model.fit(X_train_norm2, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_norm2, Y_test))\n",
    "# 10. Evaluate model on test data\n",
    "#score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
